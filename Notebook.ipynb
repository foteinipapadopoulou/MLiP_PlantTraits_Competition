{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"},{"sourceId":8145845,"sourceType":"datasetVersion","datasetId":4816952},{"sourceId":8149784,"sourceType":"datasetVersion","datasetId":4819871},{"sourceId":8178456,"sourceType":"datasetVersion","datasetId":4841404},{"sourceId":8204134,"sourceType":"datasetVersion","datasetId":4860734},{"sourceId":8332370,"sourceType":"datasetVersion","datasetId":4862895},{"sourceId":8332380,"sourceType":"datasetVersion","datasetId":4947895},{"sourceId":8409225,"sourceType":"datasetVersion","datasetId":4912621}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Notebook modified from https://www.kaggle.com/code/markwijkhuizen/planttraits2024-eda-training-pub.\n- Training only, EDA part not included.\n- Image model only, tabular data not used.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport imageio.v3 as imageio\nimport albumentations as A\n\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport timm\nimport glob\nimport torchmetrics\nimport time\nimport psutil\nimport os\n\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T10:10:42.022774Z","iopub.execute_input":"2024-06-03T10:10:42.023443Z","iopub.status.idle":"2024-06-03T10:10:52.878253Z","shell.execute_reply.started":"2024-06-03T10:10:42.023411Z","shell.execute_reply":"2024-06-03T10:10:52.877419Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class Config():\n    IMAGE_SIZE = 384\n    BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n    N_TARGETS = len(TARGET_COLUMNS)\n    TRAIN_MODEL = False\n    BUILD_PKL_DATASET = False\n    USE_SMALL_DATASET = False\n    USE_MODIFIED_TRAIN = False\n    BATCH_SIZE = 100\n    LR_MAX = 1e-4\n    WEIGHT_DECAY = 0.01\n    N_EPOCHS = 4\n    TRAIN_MODEL = True\n    IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n        \nCONFIG = Config()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T10:10:52.879886Z","iopub.execute_input":"2024-06-03T10:10:52.880265Z","iopub.status.idle":"2024-06-03T10:10:52.886611Z","shell.execute_reply.started":"2024-06-03T10:10:52.880234Z","shell.execute_reply":"2024-06-03T10:10:52.885525Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if CONFIG.BUILD_PKL_DATASET is True:\n    train = pd.read_csv('/kaggle/input/planttraits2024/train.csv')\n    train['file_path'] = train['id'].apply(lambda s: f'/kaggle/input/planttraits2024/train_images/{s}.jpeg')\n    train['jpeg_bytes'] = train['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n    train.to_pickle('train.pkl')\n    test = pd.read_csv('/kaggle/input/planttraits2024/test.csv')\n    test['file_path'] = test['id'].apply(lambda s: f'/kaggle/input/planttraits2024/test_images/{s}.jpeg')\n    test['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n    test.to_pickle('test.pkl')\nelse:\n    if CONFIG.USE_SMALL_DATASET is True:\n        train = pd.read_pickle('/kaggle/input/dataset-with-validation/small_train.pkl')       \n    elif CONFIG.USE_MODIFIED_TRAIN is True:\n        train = pd.read_pickle('/kaggle/input/dataset-with-validation/train_set.pkl')\n    else:\n         train = pd.read_pickle('/kaggle/input/baseline-model/train.pkl')\n    test = pd.read_pickle('/kaggle/input/baseline-model/test.pkl')\n    \nfor column in CONFIG.TARGET_COLUMNS:\n    lower_quantile = train[column].quantile(0.005)\n    upper_quantile = train[column].quantile(0.985)  \n    train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]\n\nCONFIG.N_TRAIN_SAMPLES = len(train)\nCONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\nCONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1\n\nprint('N_TRAIN_SAMPLES:', len(train), 'N_TEST_SAMPLES:', len(test))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:47:21.640197Z","iopub.execute_input":"2024-06-03T09:47:21.640421Z","iopub.status.idle":"2024-06-03T09:47:57.844945Z","shell.execute_reply.started":"2024-06-03T09:47:21.640402Z","shell.execute_reply":"2024-06-03T09:47:57.843913Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"N_TRAIN_SAMPLES: 49168 N_TEST_SAMPLES: 6545\n","output_type":"stream"}]},{"cell_type":"code","source":"LOG_FEATURES = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n\ny_train = np.zeros_like(train[CONFIG.TARGET_COLUMNS], dtype=np.float32)\nfor target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n    v = train[target].values\n    if target in LOG_FEATURES:\n        v = np.log10(v)\n    y_train[:, target_idx] = v\n\nSCALER = StandardScaler()\ny_train = SCALER.fit_transform(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:58:23.319492Z","iopub.execute_input":"2024-06-03T09:58:23.320245Z","iopub.status.idle":"2024-06-03T09:58:23.343409Z","shell.execute_reply.started":"2024-06-03T09:58:23.320210Z","shell.execute_reply":"2024-06-03T09:58:23.342653Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"MEAN = np.array([0.485, 0.456, 0.406])\nSTD = np.array([0.229, 0.224, 0.225])\n\nTRAIN_TRANSFORMS = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.RandomSizedCrop(\n            [448, 512],\n            CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nTEST_TRANSFORMS = A.Compose([\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nclass Dataset(Dataset):\n    def __init__(self, X_jpeg_bytes, y, transforms=None):\n        self.X_jpeg_bytes = X_jpeg_bytes\n        self.y = y\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.X_jpeg_bytes)\n\n    def __getitem__(self, index):\n        X_sample = self.transforms(\n            image=imageio.imread(self.X_jpeg_bytes[index]),\n        )['image']\n        y_sample = self.y[index]\n        \n        return X_sample, y_sample\n\ntrain_dataset = Dataset(\n    train['jpeg_bytes'].values,\n    y_train,\n    TRAIN_TRANSFORMS,\n)\n\ntrain_dataloader = DataLoader(\n        train_dataset,\n        batch_size=CONFIG.BATCH_SIZE,\n        shuffle=True,\n        drop_last=True,\n        num_workers=psutil.cpu_count(),\n)\n\ntest_dataset = Dataset(\n    test['jpeg_bytes'].values,\n    test['id'].values,\n    TEST_TRANSFORMS,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:58:24.032328Z","iopub.execute_input":"2024-06-03T09:58:24.033166Z","iopub.status.idle":"2024-06-03T09:58:24.045847Z","shell.execute_reply.started":"2024-06-03T09:58:24.033136Z","shell.execute_reply":"2024-06-03T09:58:24.044894Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = timm.create_model(\n                CONFIG.BACKBONE,\n                num_classes=CONFIG.N_TARGETS,\n                pretrained=True)\n        \n        \n    def forward(self, inputs):\n        return self.backbone(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:58:25.858476Z","iopub.execute_input":"2024-06-03T09:58:25.859061Z","iopub.status.idle":"2024-06-03T09:58:25.864796Z","shell.execute_reply.started":"2024-06-03T09:58:25.859031Z","shell.execute_reply":"2024-06-03T09:58:25.863739Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class FreezeModel(nn.Module):\n    def __init__(self, freeze_till_stage=2):\n        super().__init__()\n        self.backbone = timm.create_model(\n            CONFIG.BACKBONE,\n            num_classes=0, \n            pretrained=True\n        )\n        \n        # Freeze layers up to the specified stage\n        for name, param in self.backbone.named_parameters():\n            # This assumes layer names include the stage they belong to\n            if 'layers.' in name and int(name.split('.')[1]) < freeze_till_stage:\n                param.requires_grad = False\n\n        self.classifier = nn.Linear(self.backbone.num_features, CONFIG.N_TARGETS)\n\n    def forward(self, inputs):\n        x = self.backbone(inputs)\n        return self.classifier(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T10:12:14.633429Z","iopub.execute_input":"2024-06-03T10:12:14.633827Z","iopub.status.idle":"2024-06-03T10:12:14.641779Z","shell.execute_reply.started":"2024-06-03T10:12:14.633793Z","shell.execute_reply":"2024-06-03T10:12:14.640822Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class FeatureExtractModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = timm.create_model(\n            CONFIG.BACKBONE,\n            pretrained=True,\n            num_classes=0,\n#             global_pool='',\n        )\n    \n    def forward(self, images):\n        image_features = self.backbone(images)\n        \n        return image_features","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:58:31.119937Z","iopub.execute_input":"2024-06-03T09:58:31.120289Z","iopub.status.idle":"2024-06-03T09:58:31.126688Z","shell.execute_reply.started":"2024-06-03T09:58:31.120264Z","shell.execute_reply":"2024-06-03T09:58:31.125466Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = FreezeModel() # FeatureExtractModel()\nmodel = model.to('cuda')\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T10:12:17.262057Z","iopub.execute_input":"2024-06-03T10:12:17.262427Z","iopub.status.idle":"2024-06-03T10:12:21.401461Z","shell.execute_reply.started":"2024-06-03T10:12:17.262398Z","shell.execute_reply":"2024-06-03T10:12:21.400405Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"patch_embed.proj.weight\nTrue\npatch_embed.proj.bias\nTrue\npatch_embed.norm.weight\nTrue\npatch_embed.norm.bias\nTrue\nlayers.0.blocks.0.norm1.weight\nFalse\nlayers.0.blocks.0.norm1.bias\nFalse\nlayers.0.blocks.0.attn.relative_position_bias_table\nFalse\nlayers.0.blocks.0.attn.qkv.weight\nFalse\nlayers.0.blocks.0.attn.qkv.bias\nFalse\nlayers.0.blocks.0.attn.proj.weight\nFalse\nlayers.0.blocks.0.attn.proj.bias\nFalse\nlayers.0.blocks.0.norm2.weight\nFalse\nlayers.0.blocks.0.norm2.bias\nFalse\nlayers.0.blocks.0.mlp.fc1.weight\nFalse\nlayers.0.blocks.0.mlp.fc1.bias\nFalse\nlayers.0.blocks.0.mlp.fc2.weight\nFalse\nlayers.0.blocks.0.mlp.fc2.bias\nFalse\nlayers.0.blocks.1.norm1.weight\nFalse\nlayers.0.blocks.1.norm1.bias\nFalse\nlayers.0.blocks.1.attn.relative_position_bias_table\nFalse\nlayers.0.blocks.1.attn.qkv.weight\nFalse\nlayers.0.blocks.1.attn.qkv.bias\nFalse\nlayers.0.blocks.1.attn.proj.weight\nFalse\nlayers.0.blocks.1.attn.proj.bias\nFalse\nlayers.0.blocks.1.norm2.weight\nFalse\nlayers.0.blocks.1.norm2.bias\nFalse\nlayers.0.blocks.1.mlp.fc1.weight\nFalse\nlayers.0.blocks.1.mlp.fc1.bias\nFalse\nlayers.0.blocks.1.mlp.fc2.weight\nFalse\nlayers.0.blocks.1.mlp.fc2.bias\nFalse\nlayers.1.downsample.norm.weight\nFalse\nlayers.1.downsample.norm.bias\nFalse\nlayers.1.downsample.reduction.weight\nFalse\nlayers.1.blocks.0.norm1.weight\nFalse\nlayers.1.blocks.0.norm1.bias\nFalse\nlayers.1.blocks.0.attn.relative_position_bias_table\nFalse\nlayers.1.blocks.0.attn.qkv.weight\nFalse\nlayers.1.blocks.0.attn.qkv.bias\nFalse\nlayers.1.blocks.0.attn.proj.weight\nFalse\nlayers.1.blocks.0.attn.proj.bias\nFalse\nlayers.1.blocks.0.norm2.weight\nFalse\nlayers.1.blocks.0.norm2.bias\nFalse\nlayers.1.blocks.0.mlp.fc1.weight\nFalse\nlayers.1.blocks.0.mlp.fc1.bias\nFalse\nlayers.1.blocks.0.mlp.fc2.weight\nFalse\nlayers.1.blocks.0.mlp.fc2.bias\nFalse\nlayers.1.blocks.1.norm1.weight\nFalse\nlayers.1.blocks.1.norm1.bias\nFalse\nlayers.1.blocks.1.attn.relative_position_bias_table\nFalse\nlayers.1.blocks.1.attn.qkv.weight\nFalse\nlayers.1.blocks.1.attn.qkv.bias\nFalse\nlayers.1.blocks.1.attn.proj.weight\nFalse\nlayers.1.blocks.1.attn.proj.bias\nFalse\nlayers.1.blocks.1.norm2.weight\nFalse\nlayers.1.blocks.1.norm2.bias\nFalse\nlayers.1.blocks.1.mlp.fc1.weight\nFalse\nlayers.1.blocks.1.mlp.fc1.bias\nFalse\nlayers.1.blocks.1.mlp.fc2.weight\nFalse\nlayers.1.blocks.1.mlp.fc2.bias\nFalse\nlayers.2.downsample.norm.weight\nTrue\nlayers.2.downsample.norm.bias\nTrue\nlayers.2.downsample.reduction.weight\nTrue\nlayers.2.blocks.0.norm1.weight\nTrue\nlayers.2.blocks.0.norm1.bias\nTrue\nlayers.2.blocks.0.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.0.attn.qkv.weight\nTrue\nlayers.2.blocks.0.attn.qkv.bias\nTrue\nlayers.2.blocks.0.attn.proj.weight\nTrue\nlayers.2.blocks.0.attn.proj.bias\nTrue\nlayers.2.blocks.0.norm2.weight\nTrue\nlayers.2.blocks.0.norm2.bias\nTrue\nlayers.2.blocks.0.mlp.fc1.weight\nTrue\nlayers.2.blocks.0.mlp.fc1.bias\nTrue\nlayers.2.blocks.0.mlp.fc2.weight\nTrue\nlayers.2.blocks.0.mlp.fc2.bias\nTrue\nlayers.2.blocks.1.norm1.weight\nTrue\nlayers.2.blocks.1.norm1.bias\nTrue\nlayers.2.blocks.1.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.1.attn.qkv.weight\nTrue\nlayers.2.blocks.1.attn.qkv.bias\nTrue\nlayers.2.blocks.1.attn.proj.weight\nTrue\nlayers.2.blocks.1.attn.proj.bias\nTrue\nlayers.2.blocks.1.norm2.weight\nTrue\nlayers.2.blocks.1.norm2.bias\nTrue\nlayers.2.blocks.1.mlp.fc1.weight\nTrue\nlayers.2.blocks.1.mlp.fc1.bias\nTrue\nlayers.2.blocks.1.mlp.fc2.weight\nTrue\nlayers.2.blocks.1.mlp.fc2.bias\nTrue\nlayers.2.blocks.2.norm1.weight\nTrue\nlayers.2.blocks.2.norm1.bias\nTrue\nlayers.2.blocks.2.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.2.attn.qkv.weight\nTrue\nlayers.2.blocks.2.attn.qkv.bias\nTrue\nlayers.2.blocks.2.attn.proj.weight\nTrue\nlayers.2.blocks.2.attn.proj.bias\nTrue\nlayers.2.blocks.2.norm2.weight\nTrue\nlayers.2.blocks.2.norm2.bias\nTrue\nlayers.2.blocks.2.mlp.fc1.weight\nTrue\nlayers.2.blocks.2.mlp.fc1.bias\nTrue\nlayers.2.blocks.2.mlp.fc2.weight\nTrue\nlayers.2.blocks.2.mlp.fc2.bias\nTrue\nlayers.2.blocks.3.norm1.weight\nTrue\nlayers.2.blocks.3.norm1.bias\nTrue\nlayers.2.blocks.3.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.3.attn.qkv.weight\nTrue\nlayers.2.blocks.3.attn.qkv.bias\nTrue\nlayers.2.blocks.3.attn.proj.weight\nTrue\nlayers.2.blocks.3.attn.proj.bias\nTrue\nlayers.2.blocks.3.norm2.weight\nTrue\nlayers.2.blocks.3.norm2.bias\nTrue\nlayers.2.blocks.3.mlp.fc1.weight\nTrue\nlayers.2.blocks.3.mlp.fc1.bias\nTrue\nlayers.2.blocks.3.mlp.fc2.weight\nTrue\nlayers.2.blocks.3.mlp.fc2.bias\nTrue\nlayers.2.blocks.4.norm1.weight\nTrue\nlayers.2.blocks.4.norm1.bias\nTrue\nlayers.2.blocks.4.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.4.attn.qkv.weight\nTrue\nlayers.2.blocks.4.attn.qkv.bias\nTrue\nlayers.2.blocks.4.attn.proj.weight\nTrue\nlayers.2.blocks.4.attn.proj.bias\nTrue\nlayers.2.blocks.4.norm2.weight\nTrue\nlayers.2.blocks.4.norm2.bias\nTrue\nlayers.2.blocks.4.mlp.fc1.weight\nTrue\nlayers.2.blocks.4.mlp.fc1.bias\nTrue\nlayers.2.blocks.4.mlp.fc2.weight\nTrue\nlayers.2.blocks.4.mlp.fc2.bias\nTrue\nlayers.2.blocks.5.norm1.weight\nTrue\nlayers.2.blocks.5.norm1.bias\nTrue\nlayers.2.blocks.5.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.5.attn.qkv.weight\nTrue\nlayers.2.blocks.5.attn.qkv.bias\nTrue\nlayers.2.blocks.5.attn.proj.weight\nTrue\nlayers.2.blocks.5.attn.proj.bias\nTrue\nlayers.2.blocks.5.norm2.weight\nTrue\nlayers.2.blocks.5.norm2.bias\nTrue\nlayers.2.blocks.5.mlp.fc1.weight\nTrue\nlayers.2.blocks.5.mlp.fc1.bias\nTrue\nlayers.2.blocks.5.mlp.fc2.weight\nTrue\nlayers.2.blocks.5.mlp.fc2.bias\nTrue\nlayers.2.blocks.6.norm1.weight\nTrue\nlayers.2.blocks.6.norm1.bias\nTrue\nlayers.2.blocks.6.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.6.attn.qkv.weight\nTrue\nlayers.2.blocks.6.attn.qkv.bias\nTrue\nlayers.2.blocks.6.attn.proj.weight\nTrue\nlayers.2.blocks.6.attn.proj.bias\nTrue\nlayers.2.blocks.6.norm2.weight\nTrue\nlayers.2.blocks.6.norm2.bias\nTrue\nlayers.2.blocks.6.mlp.fc1.weight\nTrue\nlayers.2.blocks.6.mlp.fc1.bias\nTrue\nlayers.2.blocks.6.mlp.fc2.weight\nTrue\nlayers.2.blocks.6.mlp.fc2.bias\nTrue\nlayers.2.blocks.7.norm1.weight\nTrue\nlayers.2.blocks.7.norm1.bias\nTrue\nlayers.2.blocks.7.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.7.attn.qkv.weight\nTrue\nlayers.2.blocks.7.attn.qkv.bias\nTrue\nlayers.2.blocks.7.attn.proj.weight\nTrue\nlayers.2.blocks.7.attn.proj.bias\nTrue\nlayers.2.blocks.7.norm2.weight\nTrue\nlayers.2.blocks.7.norm2.bias\nTrue\nlayers.2.blocks.7.mlp.fc1.weight\nTrue\nlayers.2.blocks.7.mlp.fc1.bias\nTrue\nlayers.2.blocks.7.mlp.fc2.weight\nTrue\nlayers.2.blocks.7.mlp.fc2.bias\nTrue\nlayers.2.blocks.8.norm1.weight\nTrue\nlayers.2.blocks.8.norm1.bias\nTrue\nlayers.2.blocks.8.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.8.attn.qkv.weight\nTrue\nlayers.2.blocks.8.attn.qkv.bias\nTrue\nlayers.2.blocks.8.attn.proj.weight\nTrue\nlayers.2.blocks.8.attn.proj.bias\nTrue\nlayers.2.blocks.8.norm2.weight\nTrue\nlayers.2.blocks.8.norm2.bias\nTrue\nlayers.2.blocks.8.mlp.fc1.weight\nTrue\nlayers.2.blocks.8.mlp.fc1.bias\nTrue\nlayers.2.blocks.8.mlp.fc2.weight\nTrue\nlayers.2.blocks.8.mlp.fc2.bias\nTrue\nlayers.2.blocks.9.norm1.weight\nTrue\nlayers.2.blocks.9.norm1.bias\nTrue\nlayers.2.blocks.9.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.9.attn.qkv.weight\nTrue\nlayers.2.blocks.9.attn.qkv.bias\nTrue\nlayers.2.blocks.9.attn.proj.weight\nTrue\nlayers.2.blocks.9.attn.proj.bias\nTrue\nlayers.2.blocks.9.norm2.weight\nTrue\nlayers.2.blocks.9.norm2.bias\nTrue\nlayers.2.blocks.9.mlp.fc1.weight\nTrue\nlayers.2.blocks.9.mlp.fc1.bias\nTrue\nlayers.2.blocks.9.mlp.fc2.weight\nTrue\nlayers.2.blocks.9.mlp.fc2.bias\nTrue\nlayers.2.blocks.10.norm1.weight\nTrue\nlayers.2.blocks.10.norm1.bias\nTrue\nlayers.2.blocks.10.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.10.attn.qkv.weight\nTrue\nlayers.2.blocks.10.attn.qkv.bias\nTrue\nlayers.2.blocks.10.attn.proj.weight\nTrue\nlayers.2.blocks.10.attn.proj.bias\nTrue\nlayers.2.blocks.10.norm2.weight\nTrue\nlayers.2.blocks.10.norm2.bias\nTrue\nlayers.2.blocks.10.mlp.fc1.weight\nTrue\nlayers.2.blocks.10.mlp.fc1.bias\nTrue\nlayers.2.blocks.10.mlp.fc2.weight\nTrue\nlayers.2.blocks.10.mlp.fc2.bias\nTrue\nlayers.2.blocks.11.norm1.weight\nTrue\nlayers.2.blocks.11.norm1.bias\nTrue\nlayers.2.blocks.11.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.11.attn.qkv.weight\nTrue\nlayers.2.blocks.11.attn.qkv.bias\nTrue\nlayers.2.blocks.11.attn.proj.weight\nTrue\nlayers.2.blocks.11.attn.proj.bias\nTrue\nlayers.2.blocks.11.norm2.weight\nTrue\nlayers.2.blocks.11.norm2.bias\nTrue\nlayers.2.blocks.11.mlp.fc1.weight\nTrue\nlayers.2.blocks.11.mlp.fc1.bias\nTrue\nlayers.2.blocks.11.mlp.fc2.weight\nTrue\nlayers.2.blocks.11.mlp.fc2.bias\nTrue\nlayers.2.blocks.12.norm1.weight\nTrue\nlayers.2.blocks.12.norm1.bias\nTrue\nlayers.2.blocks.12.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.12.attn.qkv.weight\nTrue\nlayers.2.blocks.12.attn.qkv.bias\nTrue\nlayers.2.blocks.12.attn.proj.weight\nTrue\nlayers.2.blocks.12.attn.proj.bias\nTrue\nlayers.2.blocks.12.norm2.weight\nTrue\nlayers.2.blocks.12.norm2.bias\nTrue\nlayers.2.blocks.12.mlp.fc1.weight\nTrue\nlayers.2.blocks.12.mlp.fc1.bias\nTrue\nlayers.2.blocks.12.mlp.fc2.weight\nTrue\nlayers.2.blocks.12.mlp.fc2.bias\nTrue\nlayers.2.blocks.13.norm1.weight\nTrue\nlayers.2.blocks.13.norm1.bias\nTrue\nlayers.2.blocks.13.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.13.attn.qkv.weight\nTrue\nlayers.2.blocks.13.attn.qkv.bias\nTrue\nlayers.2.blocks.13.attn.proj.weight\nTrue\nlayers.2.blocks.13.attn.proj.bias\nTrue\nlayers.2.blocks.13.norm2.weight\nTrue\nlayers.2.blocks.13.norm2.bias\nTrue\nlayers.2.blocks.13.mlp.fc1.weight\nTrue\nlayers.2.blocks.13.mlp.fc1.bias\nTrue\nlayers.2.blocks.13.mlp.fc2.weight\nTrue\nlayers.2.blocks.13.mlp.fc2.bias\nTrue\nlayers.2.blocks.14.norm1.weight\nTrue\nlayers.2.blocks.14.norm1.bias\nTrue\nlayers.2.blocks.14.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.14.attn.qkv.weight\nTrue\nlayers.2.blocks.14.attn.qkv.bias\nTrue\nlayers.2.blocks.14.attn.proj.weight\nTrue\nlayers.2.blocks.14.attn.proj.bias\nTrue\nlayers.2.blocks.14.norm2.weight\nTrue\nlayers.2.blocks.14.norm2.bias\nTrue\nlayers.2.blocks.14.mlp.fc1.weight\nTrue\nlayers.2.blocks.14.mlp.fc1.bias\nTrue\nlayers.2.blocks.14.mlp.fc2.weight\nTrue\nlayers.2.blocks.14.mlp.fc2.bias\nTrue\nlayers.2.blocks.15.norm1.weight\nTrue\nlayers.2.blocks.15.norm1.bias\nTrue\nlayers.2.blocks.15.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.15.attn.qkv.weight\nTrue\nlayers.2.blocks.15.attn.qkv.bias\nTrue\nlayers.2.blocks.15.attn.proj.weight\nTrue\nlayers.2.blocks.15.attn.proj.bias\nTrue\nlayers.2.blocks.15.norm2.weight\nTrue\nlayers.2.blocks.15.norm2.bias\nTrue\nlayers.2.blocks.15.mlp.fc1.weight\nTrue\nlayers.2.blocks.15.mlp.fc1.bias\nTrue\nlayers.2.blocks.15.mlp.fc2.weight\nTrue\nlayers.2.blocks.15.mlp.fc2.bias\nTrue\nlayers.2.blocks.16.norm1.weight\nTrue\nlayers.2.blocks.16.norm1.bias\nTrue\nlayers.2.blocks.16.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.16.attn.qkv.weight\nTrue\nlayers.2.blocks.16.attn.qkv.bias\nTrue\nlayers.2.blocks.16.attn.proj.weight\nTrue\nlayers.2.blocks.16.attn.proj.bias\nTrue\nlayers.2.blocks.16.norm2.weight\nTrue\nlayers.2.blocks.16.norm2.bias\nTrue\nlayers.2.blocks.16.mlp.fc1.weight\nTrue\nlayers.2.blocks.16.mlp.fc1.bias\nTrue\nlayers.2.blocks.16.mlp.fc2.weight\nTrue\nlayers.2.blocks.16.mlp.fc2.bias\nTrue\nlayers.2.blocks.17.norm1.weight\nTrue\nlayers.2.blocks.17.norm1.bias\nTrue\nlayers.2.blocks.17.attn.relative_position_bias_table\nTrue\nlayers.2.blocks.17.attn.qkv.weight\nTrue\nlayers.2.blocks.17.attn.qkv.bias\nTrue\nlayers.2.blocks.17.attn.proj.weight\nTrue\nlayers.2.blocks.17.attn.proj.bias\nTrue\nlayers.2.blocks.17.norm2.weight\nTrue\nlayers.2.blocks.17.norm2.bias\nTrue\nlayers.2.blocks.17.mlp.fc1.weight\nTrue\nlayers.2.blocks.17.mlp.fc1.bias\nTrue\nlayers.2.blocks.17.mlp.fc2.weight\nTrue\nlayers.2.blocks.17.mlp.fc2.bias\nTrue\nlayers.3.downsample.norm.weight\nTrue\nlayers.3.downsample.norm.bias\nTrue\nlayers.3.downsample.reduction.weight\nTrue\nlayers.3.blocks.0.norm1.weight\nTrue\nlayers.3.blocks.0.norm1.bias\nTrue\nlayers.3.blocks.0.attn.relative_position_bias_table\nTrue\nlayers.3.blocks.0.attn.qkv.weight\nTrue\nlayers.3.blocks.0.attn.qkv.bias\nTrue\nlayers.3.blocks.0.attn.proj.weight\nTrue\nlayers.3.blocks.0.attn.proj.bias\nTrue\nlayers.3.blocks.0.norm2.weight\nTrue\nlayers.3.blocks.0.norm2.bias\nTrue\nlayers.3.blocks.0.mlp.fc1.weight\nTrue\nlayers.3.blocks.0.mlp.fc1.bias\nTrue\nlayers.3.blocks.0.mlp.fc2.weight\nTrue\nlayers.3.blocks.0.mlp.fc2.bias\nTrue\nlayers.3.blocks.1.norm1.weight\nTrue\nlayers.3.blocks.1.norm1.bias\nTrue\nlayers.3.blocks.1.attn.relative_position_bias_table\nTrue\nlayers.3.blocks.1.attn.qkv.weight\nTrue\nlayers.3.blocks.1.attn.qkv.bias\nTrue\nlayers.3.blocks.1.attn.proj.weight\nTrue\nlayers.3.blocks.1.attn.proj.bias\nTrue\nlayers.3.blocks.1.norm2.weight\nTrue\nlayers.3.blocks.1.norm2.bias\nTrue\nlayers.3.blocks.1.mlp.fc1.weight\nTrue\nlayers.3.blocks.1.mlp.fc1.bias\nTrue\nlayers.3.blocks.1.mlp.fc2.weight\nTrue\nlayers.3.blocks.1.mlp.fc2.bias\nTrue\nnorm.weight\nTrue\nnorm.bias\nTrue\nFreezeModel(\n  (backbone): SwinTransformer(\n    (patch_embed): PatchEmbed(\n      (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n    )\n    (layers): Sequential(\n      (0): SwinTransformerStage(\n        (downsample): Identity()\n        (blocks): Sequential(\n          (0): SwinTransformerBlock(\n            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=192, out_features=576, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=192, out_features=192, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): Identity()\n            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=192, out_features=768, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=768, out_features=192, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): Identity()\n          )\n          (1): SwinTransformerBlock(\n            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=192, out_features=576, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=192, out_features=192, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.004)\n            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=192, out_features=768, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=768, out_features=192, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.004)\n          )\n        )\n      )\n      (1): SwinTransformerStage(\n        (downsample): PatchMerging(\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (reduction): Linear(in_features=768, out_features=384, bias=False)\n        )\n        (blocks): Sequential(\n          (0): SwinTransformerBlock(\n            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=384, out_features=384, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.009)\n            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.009)\n          )\n          (1): SwinTransformerBlock(\n            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=384, out_features=384, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.013)\n            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.013)\n          )\n        )\n      )\n      (2): SwinTransformerStage(\n        (downsample): PatchMerging(\n          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n        )\n        (blocks): Sequential(\n          (0): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.017)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.017)\n          )\n          (1): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.022)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.022)\n          )\n          (2): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.026)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.026)\n          )\n          (3): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.030)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.030)\n          )\n          (4): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.035)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.035)\n          )\n          (5): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.039)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.039)\n          )\n          (6): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.043)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.043)\n          )\n          (7): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.048)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.048)\n          )\n          (8): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.052)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.052)\n          )\n          (9): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.057)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.057)\n          )\n          (10): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.061)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.061)\n          )\n          (11): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.065)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.065)\n          )\n          (12): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.070)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.070)\n          )\n          (13): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.074)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.074)\n          )\n          (14): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.078)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.078)\n          )\n          (15): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.083)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.083)\n          )\n          (16): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.087)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.087)\n          )\n          (17): SwinTransformerBlock(\n            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=768, out_features=768, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.091)\n            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.091)\n          )\n        )\n      )\n      (3): SwinTransformerStage(\n        (downsample): PatchMerging(\n          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n          (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n        )\n        (blocks): Sequential(\n          (0): SwinTransformerBlock(\n            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.096)\n            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.096)\n          )\n          (1): SwinTransformerBlock(\n            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n            (attn): WindowAttention(\n              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n              (softmax): Softmax(dim=-1)\n            )\n            (drop_path1): DropPath(drop_prob=0.100)\n            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n              (act): GELU(approximate='none')\n              (drop1): Dropout(p=0.0, inplace=False)\n              (norm): Identity()\n              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n              (drop2): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path2): DropPath(drop_prob=0.100)\n          )\n        )\n      )\n    )\n    (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n    (head): ClassifierHead(\n      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n      (drop): Dropout(p=0.0, inplace=False)\n      (fc): Identity()\n      (flatten): Identity()\n    )\n  )\n  (classifier): Linear(in_features=1536, out_features=6, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_lr_scheduler(optimizer):\n    return torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer,\n        max_lr=CONFIG.LR_MAX,\n        total_steps=CONFIG.N_STEPS,\n        pct_start=0.1,\n        anneal_strategy='cos',\n        div_factor=1e1,\n        final_div_factor=1e1,\n    )\n\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val):\n        self.sum += val.sum()\n        self.count += val.numel()\n        self.avg = self.sum / self.count\n\nMAE = torchmetrics.regression.MeanAbsoluteError().to('cuda')\nR2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to('cuda')\nLOSS = AverageMeter()\n\nY_MEAN = torch.tensor(y_train).mean(dim=0).to('cuda')\nEPS = torch.tensor([1e-6]).to('cuda')\n\ndef r2_loss(y_pred, y_true):\n    ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n    ss_total = torch.sum((y_true - Y_MEAN)**2, dim=0)\n    ss_total = torch.maximum(ss_total, EPS)\n    r2 = torch.mean(ss_res / ss_total)\n    return r2\n\nLOSS_FN = nn.SmoothL1Loss() # r2_loss\n\noptimizer = torch.optim.AdamW(\n    params=model.parameters(),\n    lr=CONFIG.LR_MAX,\n    weight_decay=CONFIG.WEIGHT_DECAY,\n)\n\nLR_SCHEDULER = get_lr_scheduler(optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:59:09.605302Z","iopub.execute_input":"2024-06-03T09:59:09.605697Z","iopub.status.idle":"2024-06-03T09:59:09.628688Z","shell.execute_reply.started":"2024-06-03T09:59:09.605667Z","shell.execute_reply":"2024-06-03T09:59:09.627619Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def extract_features(dataloader):\n    model.eval()\n    features_list = []\n    \n    with torch.no_grad():\n        for step, (X_batch, _) in enumerate(dataloader):\n            X_batch = X_batch.unsqueeze(0).to('cuda').to('cuda')\n            y_pred = model(X_batch).cpu()\n            features_list.extend(y_pred)\n    \n    features_array = np.array(features_list)\n    \n    # Convert the features array into a DataFrame\n    features_df = pd.DataFrame(features_array)\n    \n    features_df.columns = [f'feature_{i}' for i in range(features_array.shape[1])]\n    \n    return features_df\n\n#df = extract_features(train_dataloader)\n#df = extract_features(test_dataset)\n#df.to_pickle(\"swin_features_test.pkl\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:59:13.032927Z","iopub.execute_input":"2024-06-03T09:59:13.033681Z","iopub.status.idle":"2024-06-03T09:59:13.040456Z","shell.execute_reply.started":"2024-06-03T09:59:13.033651Z","shell.execute_reply":"2024-06-03T09:59:13.039489Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:59:15.025466Z","iopub.execute_input":"2024-06-03T09:59:15.026315Z","iopub.status.idle":"2024-06-03T09:59:15.030933Z","shell.execute_reply.started":"2024-06-03T09:59:15.026282Z","shell.execute_reply":"2024-06-03T09:59:15.029766Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if CONFIG.TRAIN_MODEL is True:\n    print(\"Start Training:\")\n    for epoch in range(CONFIG.N_EPOCHS):\n        MAE.reset()\n        R2.reset()\n        LOSS.reset()\n        model.train()\n\n        for step, (X_batch, y_true) in enumerate(train_dataloader):\n            X_batch = X_batch.to('cuda')\n            y_true = y_true.to('cuda')\n            t_start = time.perf_counter_ns()\n            y_pred = model(X_batch)\n            loss = LOSS_FN(y_pred, y_true)\n            LOSS.update(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            LR_SCHEDULER.step()\n            MAE.update(y_pred, y_true)\n            R2.update(y_pred, y_true)\n\n            if not CONFIG.IS_INTERACTIVE and (step+1) == CONFIG.N_STEPS_PER_EPOCH:\n                print(\n                    f'EPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n                    f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n                )\n            elif CONFIG.IS_INTERACTIVE:\n                print(\n                    f'\\rEPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n                    f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n                    end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n                )\n\n    torch.save(model, 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T09:59:15.757067Z","iopub.execute_input":"2024-06-03T09:59:15.757693Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Start Training:\nEPOCH 01, 0081/4916 | loss: 0.4142, mae: 0.7822, r2: 0.0382, step: 2.137s, lr: 1.02e-055","output_type":"stream"}]},{"cell_type":"code","source":"SUBMISSION_ROWS = []\nmodel.eval()\n\nfor X_sample_test, test_id in tqdm(test_dataset):\n    with torch.no_grad():\n        y_pred = model(X_sample_test.unsqueeze(0).to('cuda')).detach().cpu().numpy()\n    \n    y_pred = SCALER.inverse_transform(y_pred).squeeze()\n    row = {'id': test_id}\n    \n    for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n        if k in LOG_FEATURES:\n            row[k.replace('_mean', '')] = 10 ** v\n        else:\n            row[k.replace('_mean', '')] = v\n\n    SUBMISSION_ROWS.append(row)\n    \nsubmission_df = pd.DataFrame(SUBMISSION_ROWS)\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submit!\")","metadata":{"execution":{"iopub.status.busy":"2024-05-30T15:52:25.780148Z","iopub.status.idle":"2024-05-30T15:52:25.780485Z","shell.execute_reply.started":"2024-05-30T15:52:25.780326Z","shell.execute_reply":"2024-05-30T15:52:25.780340Z"},"trusted":true},"execution_count":null,"outputs":[]}]}