{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"},{"sourceId":8145845,"sourceType":"datasetVersion","datasetId":4816952}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Notebook modified from https://www.kaggle.com/code/markwijkhuizen/planttraits2024-eda-training-pub.\n- Training only, EDA part not included.\n- Image model only, tabular data not used.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport imageio.v3 as imageio\nimport albumentations as A\n\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport timm\nimport glob\nimport torchmetrics\nimport time\nimport psutil\nimport os\n\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:00:26.720179Z","iopub.execute_input":"2024-04-17T12:00:26.720461Z","iopub.status.idle":"2024-04-17T12:00:37.864708Z","shell.execute_reply.started":"2024-04-17T12:00:26.720436Z","shell.execute_reply":"2024-04-17T12:00:37.863895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config():\n    IMAGE_SIZE = 384\n    BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n    N_TARGETS = len(TARGET_COLUMNS)\n    BATCH_SIZE = 10\n    LR_MAX = 1e-4\n    WEIGHT_DECAY = 0.01\n    N_EPOCHS = 6\n    TRAIN_MODEL = False\n    IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n        \nCONFIG = Config()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:00:37.866164Z","iopub.execute_input":"2024-04-17T12:00:37.866448Z","iopub.status.idle":"2024-04-17T12:00:37.872183Z","shell.execute_reply.started":"2024-04-17T12:00:37.866424Z","shell.execute_reply":"2024-04-17T12:00:37.871084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.TRAIN_MODEL is True:\n    train = pd.read_csv('/kaggle/input/planttraits2024/train.csv')\n    train['file_path'] = train['id'].apply(lambda s: f'/kaggle/input/planttraits2024/train_images/{s}.jpeg')\n    train['jpeg_bytes'] = train['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n    train.to_pickle('train.pkl')\nelse:\n    train = pd.read_pickle('/kaggle/input/baseline-model/train.pkl')\n\nfor column in CONFIG.TARGET_COLUMNS:\n    lower_quantile = train[column].quantile(0.005)\n    upper_quantile = train[column].quantile(0.985)  \n    train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]\n\nCONFIG.N_TRAIN_SAMPLES = len(train)\nCONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\nCONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1\n\nif CONFIG.TRAIN_MODEL is True:\n    test = pd.read_csv('/kaggle/input/planttraits2024/test.csv')\n    test['file_path'] = test['id'].apply(lambda s: f'/kaggle/input/planttraits2024/test_images/{s}.jpeg')\n    test['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n    test.to_pickle('test.pkl')\nelse:\n    test = pd.read_pickle('/kaggle/input/baseline-model/test.pkl')\n\nprint('N_TRAIN_SAMPLES:', len(train), 'N_TEST_SAMPLES:', len(test))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:01:31.934664Z","iopub.execute_input":"2024-04-17T12:01:31.935051Z","iopub.status.idle":"2024-04-17T12:01:34.706515Z","shell.execute_reply.started":"2024-04-17T12:01:31.935009Z","shell.execute_reply":"2024-04-17T12:01:34.705557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LOG_FEATURES = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n\ny_train = np.zeros_like(train[CONFIG.TARGET_COLUMNS], dtype=np.float32)\nfor target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n    v = train[target].values\n    if target in LOG_FEATURES:\n        v = np.log10(v)\n    y_train[:, target_idx] = v\n\nSCALER = StandardScaler()\ny_train = SCALER.fit_transform(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:02:08.057989Z","iopub.execute_input":"2024-04-17T12:02:08.058739Z","iopub.status.idle":"2024-04-17T12:02:08.082224Z","shell.execute_reply.started":"2024-04-17T12:02:08.058704Z","shell.execute_reply":"2024-04-17T12:02:08.081425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MEAN = np.array([0.485, 0.456, 0.406])\nSTD = np.array([0.229, 0.224, 0.225])\n\nTRAIN_TRANSFORMS = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.RandomSizedCrop(\n            [448, 512],\n            CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nTEST_TRANSFORMS = A.Compose([\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.ToFloat(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nclass Dataset(Dataset):\n    def __init__(self, X_jpeg_bytes, y, transforms=None):\n        self.X_jpeg_bytes = X_jpeg_bytes\n        self.y = y\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.X_jpeg_bytes)\n\n    def __getitem__(self, index):\n        X_sample = self.transforms(\n            image=imageio.imread(self.X_jpeg_bytes[index]),\n        )['image']\n        y_sample = self.y[index]\n        \n        return X_sample, y_sample\n\ntrain_dataset = Dataset(\n    train['jpeg_bytes'].values,\n    y_train,\n    TRAIN_TRANSFORMS,\n)\n\ntrain_dataloader = DataLoader(\n        train_dataset,\n        batch_size=CONFIG.BATCH_SIZE,\n        shuffle=True,\n        drop_last=True,\n        num_workers=psutil.cpu_count(),\n)\n\ntest_dataset = Dataset(\n    test['jpeg_bytes'].values,\n    test['id'].values,\n    TEST_TRANSFORMS,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:02:08.359947Z","iopub.execute_input":"2024-04-17T12:02:08.360805Z","iopub.status.idle":"2024-04-17T12:02:08.374312Z","shell.execute_reply.started":"2024-04-17T12:02:08.360769Z","shell.execute_reply":"2024-04-17T12:02:08.373384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = timm.create_model(\n                CONFIG.BACKBONE,\n                num_classes=CONFIG.N_TARGETS,\n                pretrained=True)\n        \n    def forward(self, inputs):\n        return self.backbone(inputs)\n\nmodel = Model()\nmodel = model.to('cuda')\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:02:08.740651Z","iopub.execute_input":"2024-04-17T12:02:08.740976Z","iopub.status.idle":"2024-04-17T12:02:16.336782Z","shell.execute_reply.started":"2024-04-17T12:02:08.740949Z","shell.execute_reply":"2024-04-17T12:02:16.335796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_scheduler(optimizer):\n    return torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer,\n        max_lr=CONFIG.LR_MAX,\n        total_steps=CONFIG.N_STEPS,\n        pct_start=0.1,\n        anneal_strategy='cos',\n        div_factor=1e1,\n        final_div_factor=1e1,\n    )\n\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val):\n        self.sum += val.sum()\n        self.count += val.numel()\n        self.avg = self.sum / self.count\n\nMAE = torchmetrics.regression.MeanAbsoluteError().to('cuda')\nR2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to('cuda')\nLOSS = AverageMeter()\n\nY_MEAN = torch.tensor(y_train).mean(dim=0).to('cuda')\nEPS = torch.tensor([1e-6]).to('cuda')\n\ndef r2_loss(y_pred, y_true):\n    ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n    ss_total = torch.sum((y_true - Y_MEAN)**2, dim=0)\n    ss_total = torch.maximum(ss_total, EPS)\n    r2 = torch.mean(ss_res / ss_total)\n    return r2\n\nLOSS_FN = nn.SmoothL1Loss() # r2_loss\n\noptimizer = torch.optim.AdamW(\n    params=model.parameters(),\n    lr=CONFIG.LR_MAX,\n    weight_decay=CONFIG.WEIGHT_DECAY,\n)\n\nLR_SCHEDULER = get_lr_scheduler(optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:02:16.338716Z","iopub.execute_input":"2024-04-17T12:02:16.339357Z","iopub.status.idle":"2024-04-17T12:02:16.358622Z","shell.execute_reply.started":"2024-04-17T12:02:16.339319Z","shell.execute_reply":"2024-04-17T12:02:16.357830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.TRAIN_MODEL is True:\n    print(\"Start Training:\")\n    for epoch in range(CONFIG.N_EPOCHS):\n        MAE.reset()\n        R2.reset()\n        LOSS.reset()\n        model.train()\n\n        for step, (X_batch, y_true) in enumerate(train_dataloader):\n            X_batch = X_batch.to('cuda')\n            y_true = y_true.to('cuda')\n            t_start = time.perf_counter_ns()\n            y_pred = model(X_batch)\n            loss = LOSS_FN(y_pred, y_true)\n            LOSS.update(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            LR_SCHEDULER.step()\n            MAE.update(y_pred, y_true)\n            R2.update(y_pred, y_true)\n\n            if not CONFIG.IS_INTERACTIVE and (step+1) == CONFIG.N_STEPS_PER_EPOCH:\n                print(\n                    f'EPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n                    f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n                )\n            elif CONFIG.IS_INTERACTIVE:\n                print(\n                    f'\\rEPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' + \n                    f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n                    f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n                    end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n                )\n\n    torch.save(model, 'model.pth')\nelse:\n    model = torch.load('/kaggle/input/baseline-model/model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:02:16.360035Z","iopub.execute_input":"2024-04-17T12:02:16.360361Z","iopub.status.idle":"2024-04-17T12:02:22.706146Z","shell.execute_reply.started":"2024-04-17T12:02:16.360336Z","shell.execute_reply":"2024-04-17T12:02:22.705313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUBMISSION_ROWS = []\nmodel.eval()\n\nfor X_sample_test, test_id in tqdm(test_dataset):\n    with torch.no_grad():\n        y_pred = model(X_sample_test.unsqueeze(0).to('cuda')).detach().cpu().numpy()\n    \n    y_pred = SCALER.inverse_transform(y_pred).squeeze()\n    row = {'id': test_id}\n    \n    for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n        if k in LOG_FEATURES:\n            row[k.replace('_mean', '')] = 10 ** v\n        else:\n            row[k.replace('_mean', '')] = v\n\n    SUBMISSION_ROWS.append(row)\n    \nsubmission_df = pd.DataFrame(SUBMISSION_ROWS)\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submit!\")","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:02:22.708456Z","iopub.execute_input":"2024-04-17T12:02:22.708788Z","iopub.status.idle":"2024-04-17T12:08:23.913465Z","shell.execute_reply.started":"2024-04-17T12:02:22.708763Z","shell.execute_reply":"2024-04-17T12:08:23.912576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}